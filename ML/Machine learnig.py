import pandas as pd
import joblib
import os
import re
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.utils import resample

# ====================
# CONFIGURA√á√ïES
# ====================
ARQUIVO_ENTRADA = "ocorrencias_industriais.csv"
ARQUIVO_ROTULADO = "ocorrencias_rotuladas.csv"
ARQUIVO_MODELO = "modelo_manutencao.joblib"
ARQUIVO_SAIDA = "ocorrencias_classificadas.csv"
SEED = 42

# ====================
# PR√â-PROCESSAMENTO
# ====================
def preprocessar_texto(texto):
    """Limpa e normaliza textos para melhorar a extra√ß√£o de features"""
    if not isinstance(texto, str):
        return ""
    
    # Convers√£o para min√∫sculas
    texto = texto.lower()
    # Remo√ß√£o de caracteres especiais e n√∫meros
    texto = re.sub(r'[^\w\s]', ' ', texto)
    texto = re.sub(r'\d+', ' ', texto)
    # Redu√ß√£o de espa√ßos m√∫ltiplos
    texto = re.sub(r'\s+', ' ', texto).strip()
    return texto

# ====================
# BALANCEAMENTO DE DADOS
# ====================
def balancear_dados(df, coluna_alvo):
    """Balanceia classes minorit√°rias atrav√©s de oversampling"""
    classes = df[coluna_alvo].unique()
    max_size = max(df[coluna_alvo].value_counts())
    
    dfs_balanceados = []
    for classe in classes:
        df_classe = df[df[coluna_alvo] == classe]
        if len(df_classe) < max_size:
            df_classe = resample(df_classe,
                                 replace=True,
                                 n_samples=max_size,
                                 random_state=SEED)
        dfs_balanceados.append(df_classe)
    
    return pd.concat(dfs_balanceados)

# ====================
# GERAR RECOMENDA√á√ïES
# ====================
def gerar_recomendacao(classe):
    """Gera recomenda√ß√µes t√©cnicas baseadas na classe predita"""
    respostas = {
        "falha_mecanica": "üîß [Prioridade Alta] Verificar sistemas mec√¢nicos: lubrifica√ß√£o, acoplamentos e rolamentos. Realizar an√°lise vibracional.",
        "falha_eletrica": "‚ö° [Prioridade Alta] Inspecionar cabos, conex√µes e alimenta√ß√£o el√©trica. Verificar isolamento t√©rmico e carga dos circuitos.",
        "vazamento": "üíß [Prioridade Urgente] Verificar juntas, v√°lvulas e estanqueidade dos dutos. Monitorar pontos cr√≠ticos com termografia.",
        "sobreaquecimento": "üå°Ô∏è [Prioridade Urgente] Avaliar sistemas de refrigera√ß√£o e ventila√ß√£o for√ßada. Verificar limpeza de trocadores de calor.",
        "vibracao_excessiva": "üîé [Prioridade M√©dia] Checar balanceamento e alinhamento de rotores. Inspecionar funda√ß√µes e fixa√ß√µes mec√¢nicas.",
        "pre_alarme": "‚ö†Ô∏è [Preventivo] Iniciar verifica√ß√£o preventiva antes da parada. Agendar manuten√ß√£o programada.",
        "normal": "‚úÖ [Operacional] Nenhuma a√ß√£o corretiva necess√°ria no momento. Continuar monitoramento rotineiro.",
        "outros": "üìã [Diagn√≥stico] Revis√£o t√©cnica necess√°ria. Coletar mais dados para an√°lise detalhada."
    }
    return respostas.get(classe, "üìã [Diagn√≥stico] Revis√£o t√©cnica necess√°ria. Coletar mais dados para an√°lise detalhada.")

# ====================
# VALIDA√á√ÉO INICIAL
# ====================
print("üîç Validando arquivos e dados...")
for arquivo in [ARQUIVO_ENTRADA, ARQUIVO_ROTULADO]:
    if not os.path.exists(arquivo):
        print(f"‚ùå Arquivo n√£o encontrado: {arquivo}")
        exit()

# Carregar dados rotulados
try:
    train_df = pd.read_csv(ARQUIVO_ROTULADO)
    required_columns = ['descricao', 'classe']
    if not all(col in train_df.columns for col in required_columns):
        print(f"‚ùå Arquivo de treinamento precisa das colunas: {required_columns}")
        exit()
except Exception as e:
    print(f"‚ùå Erro ao ler arquivo de treinamento: {str(e)}")
    exit()

# ====================
# PREPARA√á√ÉO DOS DADOS
# ====================
print("\nüßπ Pr√©-processando dados...")
train_df['descricao'] = train_df['descricao'].apply(preprocessar_texto)

# Balanceamento de classes
print("‚öñÔ∏è Balanceando classes...")
train_df = balancear_dados(train_df, 'classe')

X = train_df["descricao"]
y = train_df["classe"]

# ====================
# TREINAMENTO DO MODELO
# ====================
print("\nüéØ Treinando modelo preditivo...")
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=SEED
)

modelo = Pipeline([
    ("tfidf", TfidfVectorizer(
        max_features=10000,
        ngram_range=(1, 3),
    ),
    ("clf", MultinomialNB(alpha=0.01))
])

modelo.fit(X_train, y_train)

# ====================
# AVALIA√á√ÉO DO MODELO
# ====================
print("\nüìä Avaliando performance do modelo...")
y_pred = modelo.predict(X_test)

print("\nüìù Relat√≥rio de classifica√ß√£o:")
print(classification_report(y_test, y_pred, digits=4))

# Matriz de confus√£o
plt.figure(figsize=(10, 8))
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, 
            annot=True, 
            fmt='d', 
            cmap='Blues',
            xticklabels=modelo.classes_,
            yticklabels=modelo.classes_)
plt.title("Matriz de Confus√£o - Classifica√ß√£o de Falhas")
plt.xlabel('Predito')
plt.ylabel('Real')
plt.savefig("matriz_confusao_manutencao.png", bbox_inches='tight', dpi=300)
print("\nüìà Matriz de confus√£o salva em alta resolu√ß√£o")

# ====================
# SALVAR MODELO
# ====================
joblib.dump(modelo, ARQUIVO_MODELO)
print(f"\n‚úÖ Modelo salvo como '{ARQUIVO_MODELO}'")

# ====================
# CLASSIFICA√á√ÉO FINAL
# ====================
print("\nüîé Classificando novas ocorr√™ncias...")
try:
    input_df = pd.read_csv(ARQUIVO_ENTRADA)
    input_df['descricao'] = input_df['descricao'].apply(preprocessar_texto)
    input_df["classe_predita"] = modelo.predict(input_df["descricao"])
    
    # Adicionar probabilidades das predi√ß√µes
    probabilidades = modelo.predict_proba(input_df["descricao"])
    for i, classe in enumerate(modelo.classes_):
        input_df[f'prob_{classe}'] = probabilidades[:, i]
    
    # Gerar recomenda√ß√µes
    input_df["recomendacao"] = input_df["classe_predita"].apply(gerar_recomendacao)
    
    # Ordenar por criticidade
    ordem_criticidade = {
        'vazamento': 1,
        'sobreaquecimento': 2,
        'falha_eletrica': 3,
        'falha_mecanica': 4,
        'vibracao_excessiva': 5,
        'pre_alarme': 6,
        'normal': 7,
        'outros': 8
    }
    input_df['prioridade'] = input_df['classe_predita'].map(ordem_criticidade)
    input_df = input_df.sort_values('prioridade')
    
    input_df.to_csv(ARQUIVO_SAIDA, index=False)
    print(f"üìÑ Dados classificados salvos em '{ARQUIVO_SAIDA}'")
    print("\n‚úÖ Processo conclu√≠do com sucesso!")

except Exception as e:
    print(f"‚ùå Erro durante classifica√ß√£o: {str(e)}")